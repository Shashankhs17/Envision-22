{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Envision 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing and Loading the URDF/SDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybullet as p\n",
    "\n",
    "physicsClientID = p.connect(p.GUI)\n",
    "\n",
    "import pybullet_data\n",
    "\n",
    "p.setAdditionalSearchPath(pybullet_data.getDataPath())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFiles():\n",
    "    plane = p.loadURDF('plane.urdf')\n",
    "\n",
    "    robot_StartPos = [0,0,0]\n",
    "    robot_StartOrientation = p.getQuaternionFromEuler([0,0,0])\n",
    "\n",
    "    robot = p.loadSDF(\"/kuka_iiwa/kuka_with_gripper2.sdf\")[0]\n",
    "    p.resetBasePositionAndOrientation(robot, robot_StartPos, robot_StartOrientation)\n",
    "\n",
    "    numOfJoints = p.getNumJoints(robot)\n",
    "\n",
    "    print(f\"Plane = {plane} \\nStart Position = {robot_StartPos} \\nStart Orientation = {robot_StartOrientation} \\nRobot = {robot} \\nNumber of joints = {numOfJoints}\")\n",
    "\n",
    "    # print(\"Joint Details :\")\n",
    "    # for i in range(numOfJoints):\n",
    "    #     print(p.getJointInfo(robot, i))\n",
    "        \n",
    "    return plane, robot, robot_StartPos, robot_StartOrientation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImage(robot) :\n",
    "    \n",
    "    # The Camera will be placed on the Link 7 and will always be looking downwards\n",
    "    \n",
    "    # The Position and orientation of the Link 7 will be used to determine the camera position and orientation\n",
    "    cameraPosition = p.getLinkState(robot, 7)[0]\n",
    "    cameraOrientation = p.getEulerFromQuaternion(p.getLinkState(robot, 7)[1])\n",
    "\n",
    "    print(f\"\\nCamera Position: {cameraPosition} \\nCamera Orientation: {cameraOrientation}\")\n",
    "    \n",
    "    gainX = gainY = gainZ = 2\n",
    "    \n",
    "    if cameraOrientation[0] < 0:\n",
    "        gainX = -2\n",
    "        \n",
    "    if cameraOrientation[1] < 0:\n",
    "        gainY = -2\n",
    "        \n",
    "    if cameraOrientation[2] < 0:\n",
    "        gainZ = -2\n",
    "\n",
    "    # The viewMatrix The camera view matrix is a complicated 4x4 matrix, but in simplest terms it describes where the camera is and in what direction it is pointing. There are some useful helper functions for creating this matrix by specifying position and rotation more directly. The function computeViewMatrix can create this matrix in exchange for three vectors.\n",
    "    viewMatrix = p.computeViewMatrix(\n",
    "        # cameraEyePosition describes the physical location of the camera in x, y, and z coordinates\n",
    "        cameraEyePosition = cameraPosition,\n",
    "        # cameraTargetPosition describes the point that we wish the camera to face : Negative Z direction, that is downwards\n",
    "        cameraTargetPosition = [cameraOrientation[0] * 100 , cameraOrientation[1] * 100, cameraOrientation[2] * -100],\n",
    "        # cameraUpVector describes the orientation of the camera\n",
    "        cameraUpVector = [cameraOrientation[0] * 1 , cameraOrientation[1] * 1, cameraOrientation[2] * -1])\n",
    "\n",
    "    # The projection matrix, much like the view matrix, can be created using a few helper functions. In this case, the computeProjectionMatrixFOV function describes our camera’s intrinsic properties in the simplest and most pertinent ways to our use case.\n",
    "    projectionMatrix = p.computeProjectionMatrixFOV(\n",
    "        # Field of View\n",
    "        fov = 45.0,\n",
    "        # Aspect ratio\n",
    "        aspect = 1.0,\n",
    "        # The minimum distance the camera will render objects\n",
    "        nearVal = 0.1,\n",
    "        # The maximum distance the camera will render objects\n",
    "        farVal = 10.1)\n",
    "\n",
    "    # This function returns three image buffers: rgbImg, depthImg, and segImg. rgbImg is a uint8 image with red, green, blue, and alpha channels of the camera’s visuals. depthImg is a floating-point grayscale image that describes the distance of individual rendered pixels from the camera. It can be used to model the field-of-view of a real-world depth sensor. Lastly, segImg is a segmentation mask of the image where pixels each contain unique integers with object IDs. These are invaluable for training segmentation algorithms for robotic agents, such as a robotic arm that needs to identify objects to sort into respective bins or for a driverless car that wants to identify pedestrians, street signs, and roads.\n",
    "    width, height, rgbImg, depthImg, segImg = p.getCameraImage(\n",
    "        # Width of the image in pixels\n",
    "        width = 224, \n",
    "        # Height of the image in pixels\n",
    "        height = 224,\n",
    "        # view matrix as the one deifined above\n",
    "        viewMatrix = viewMatrix,\n",
    "        # projectionMatrix as the one deifined above\n",
    "        projectionMatrix = projectionMatrix)\n",
    "    \n",
    "    return width, height, rgbImg, depthImg, segImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane, robot, robot_StartPos, robot_StartOrientation = loadFiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height, rgbImg, depthImg, segImg = getImage(robot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.setRealTimeSimulation(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.setRealTimeSimulation(0)\n",
    "p.resetSimulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Joint Details :\")\n",
    "for i in range(14):\n",
    "    # print(p.getJointInfo(robot, i)[0:3], p.getJointInfo(robot, i)[8:10])\n",
    "    print(p.getJointInfo(robot, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.setJointMotorControlArray(robot, [8, 11], p.POSITION_CONTROL, targetPositions=[0.0,0], forces = [0.0001]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.setJointMotorControl2(robot, 1, p.VELOCITY_CONTROL, targetVelocity = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.setJointMotorControl2(robot, 1, p.VELOCITY_CONTROL, targetVelocity = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.getLinkState(robot, 8)[0], \"\\n\", p.getEulerFromQuaternion(p.getLinkState(robot,8)[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
